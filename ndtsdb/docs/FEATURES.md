# ndtsdb Features

> ndtsdb 的 scope / non-goals：见 `docs/SCOPE.md`。

本文档列出 **ndtsdb 引擎本体**已具备的主要能力（用于发布仓库/产品说明）。

---

## 1. Compression Algorithms

ndtsdb 提供多种压缩算法，适用于不同数据类型和模式：

### Gorilla Compression
- **用途**：浮点数时序数据（价格、指标等）
- **算法**：Delta-of-Delta + XOR（Facebook 开源）
- **压缩率**：20-30%（真实浮点数），97%（常量值）
- **类型**：float64
- **实现**：纯 TypeScript（GorillaEncoder）
- **注意**：对随机浮点数压缩率较低（~20%），但对平滑/重复数据效果好

### Delta Encoding
- **用途**：单调递增序列（timestamp, ID）
- **算法**：存储相邻值差值（Varint 编码）
- **压缩率**：75%（等间隔序列）
- **类型**：int64, int32

### Delta-of-Delta
- **用途**：等间隔时间序列（固定周期采样）
- **算法**：存储差值的差值
- **压缩率**：>90%（等间隔）

### RLE (Run-Length Encoding)
- **用途**：重复值多的序列（状态、symbol ID）
- **算法**：游程编码（value + count）
- **压缩率**：>95%（高重复率数据）

**当前集成状态**：
- ✅ 压缩算法已实现（compression.ts）+ 基准测试
- ✅ **已集成到 AppendWriter 文件格式**（可选开关，向后兼容旧文件）

### AppendWriter 启用压缩
```ts
const writer = new AppendWriter(path, columns, {
  compression: {
    enabled: true,
    algorithms: {
      timestamp: 'delta',    // int64: 单调递增 → Delta
      price: 'gorilla',      // float64: 浮点数 → Gorilla
      symbol_id: 'rle',      // int32: 重复值 → RLE
    },
  },
});
```
- **支持算法**：
  - `delta`：int64/int32 单调递增序列
  - `rle`：int32 重复值序列
  - `gorilla`：float64 浮点数时序数据
  - `none`：不压缩
- **文件格式**：
  - 压缩启用时：chunk 写入为 `rowCount + (colLen+colData)*N + crc32`
  - 未启用压缩：保持旧格式（固定列长），读取端自动兼容
- **自动选择**：不指定 algorithms 时，自动选择最优算法
  - int64 → delta
  - int32 → delta
  - float64 → gorilla

---

## 2. Partitioned Tables

**自动分区**：按时间/symbol/hash 自动分区，提升大表查询性能。

### 分区策略
- **时间分区**：按 day/month/year 自动分区（如 K线数据按日分区）
- **范围分区**：按数值范围分区
- **哈希分区**：按列值哈希分桶（均匀分布）

### 使用示例
```typescript
const table = new PartitionedTable(
  '/data/klines',
  [{ name: 'timestamp', type: 'int64' }, { name: 'price', type: 'float64' }],
  { type: 'time', column: 'timestamp', interval: 'day' } // 按天分区
);

// 写入自动分区
table.append([
  { timestamp: 1704153600000n, price: 100.5 },
  { timestamp: 1704240000000n, price: 101.2 },
]);

// 跨分区查询
const results = table.query(row => row.price > 100);
```

### 特性
- ✅ 自动分区文件管理（写入时选择/创建分区）
- ✅ 跨分区查询合并
- ✅ 分区元数据（行数、边界信息）
- ✅ WHERE 时间范围优化 v1：`query(filter, {min,max})` 提前过滤分区扫描（按分区 label 推断范围）
- ✅ **SQL 集成**：`queryPartitionedTableToColumnar()`自动提取 WHERE 时间范围并转换为内存表供 SQL 执行

### SQL 集成示例
```typescript
const partitionedTable = new PartitionedTable(...);
const sql = "SELECT * FROM t WHERE timestamp >= 1000";
const parsed = new SQLParser().parse(sql);

// 自动提取时间范围 + 优化分区扫描 + 转换为 ColumnarTable
const table = queryPartitionedTableToColumnar(partitionedTable, parsed.data.whereExpr);

// 注册并执行 SQL
executor.registerTable('t', table);
const result = executor.execute(parsed);
```

---

## 3. Streaming Aggregation

**增量窗口计算**：实时指标计算，无需全量重算。

### 支持的聚合器
- **StreamingSMA**：滑动平均
- **StreamingEMA**：指数移动平均
- **StreamingStdDev**：滑动标准差
- **StreamingMin/Max**：滑动最小/最大值
- **StreamingAggregator**：多指标组合计算

### 使用示例
```typescript
const sma = new StreamingSMA(20); // 20-period SMA

// 实时添加新数据
const avgPrice1 = sma.add(100.5);
const avgPrice2 = sma.add(101.2);
// ...

// 多指标计算
const agg = new StreamingAggregator();
agg.addAggregator('sma', new StreamingSMA(20));
agg.addAggregator('ema', new StreamingEMA(12));
agg.addAggregator('stddev', new StreamingStdDev(20));

const metrics = agg.add(100.5); // { sma: ..., ema: ..., stddev: ... }
```

### 应用场景
- 实时监控仪表盘
- 在线交易系统指标
- 动态警报触发
- 流式数据处理

---

## 4. Storage Engine

### AppendWriter (DLv2)
- chunked append-only
- header + per-chunk CRC32（固定 4KB header 预留空间）
- reopen & append 无需重写
- **列压缩（可选）**：压缩启用时 chunk 使用变长列格式（colLen + colData），读取端自动解压
  - int64: delta
  - int32: delta / rle
  - float64: 暂未集成（后续可接 Gorilla）
- **String 持久化**：字典编码（string → int32 id），存储在 header.stringDicts
- **Tombstone 删除**：`deleteWhereWithTombstone`（O(1) 标记 + 延迟 compact）
  - 独立 .tomb 文件（RoaringBitmap 压缩存储已删除行号）
  - `compact()` 清理 tombstone + 重写文件
  - `readAllFiltered()` 自动过滤已删除行
- **自动 compact**：多触发条件，close 时自动清理 + 合并 chunk
  - `autoCompact`: true/false（默认 false）
  - 触发条件（任一满足即触发）：
    - `compactThreshold`: tombstone 比例（默认 0.2 = 20%）
    - `compactMaxAgeMs`: 最大未 compact 时间（默认 24h）
    - `compactMaxFileSize`: 最大文件大小（默认 100MB）
    - `compactMaxChunks`: 最大 chunk 数量（默认 1000）
    - `compactMaxWrites`: 累计写入行数（默认 100k）
  - `compactMinRows`: 1000（最小行数阈值，避免小表频繁 compact）
- **rewrite/compact**：`rewrite/deleteWhere/updateWhere`（写 tmp + 原子替换，向后兼容）

### ColumnarTable
- 内存列式表
- 数值列使用 TypedArray
- **string 列支持持久化**（字典编码，透明存储为 int32 id）

### SymbolTable
- 字典编码：string → int

---

## 2. Query / Analytics

### 2.1 SQL 子集

- SELECT / FROM（单表 + JOIN）
- WHERE（括号优先级 + AND/OR/NOT；基础比较 + LIKE + IN）
- JOIN（INNER/LEFT；ON 目前支持等值 + AND 链）
- ORDER BY（列名 / alias / ordinal(ORDER BY 1) / 标量表达式；多 key 支持 ASC/DESC）
- LIMIT / OFFSET
- GROUP BY（基础聚合）
- HAVING（GROUP BY 后过滤；支持 alias/标量表达式条件）
- CTE / WITH（materialize 临时表）
- 子查询（FROM (SELECT ...) 派生表；WHERE col IN (SELECT ...)）
- CREATE TABLE / INSERT / UPSERT

### 2.2 标量表达式（SQLite/DuckDB 常用子集）

- 运算符：`+ - * / %`、括号
- 字符串拼接：`||`
- 常用函数：`ROUND/SQRT/ABS/LN/LOG/EXP/POW(MIN/MAX)`

### 2.3 窗口函数

支持 `... OVER (PARTITION BY ... ORDER BY ... ROWS BETWEEN N PRECEDING AND CURRENT ROW)`：
- `STDDEV/VARIANCE`
- `COUNT/SUM/AVG/MIN/MAX`
- `ROW_NUMBER`

#### Inline Window
- 支持表达式中嵌套窗口函数，例如：
  - `STDDEV(close) OVER (...) / price * 100`

#### PARTITION BY fast-path
- 专门优化模式：`CTE + PARTITION BY + ROW_NUMBER + WHERE rn = 1`
- 用于“每分区只取最后一行 + 多个窗口指标”的典型时序报表场景

---

## 3. Time-series Extensions

- `sampleBy()` / `ohlcv()`
- `latestOn()`
- `movingAverage()` / `exponentialMovingAverage()` / `rollingStdDev()`

---

## 4. Native Acceleration (libndts)

- 可选 native 加速（8 平台预编译）
- 自动 JS fallback（无原生库/非 Bun 环境也可运行）

---

## 5. Index（索引）

- **BTree 索引**：数值列（timestamp/price 等）范围查询加速
- **复合索引**：多列组合查询加速（如 (symbol, timestamp) 或 (region, city, timestamp)）
  - 嵌套 Map + BTree 结构（支持 N 列）
  - 支持前缀精确匹配 + 最后一列范围查询
  - 自动维护（appendBatch 时更新）
- **SQL 自动优化**：WHERE 条件自动使用索引（> / < / >= / <= / =）
  - N 列复合索引前缀匹配（如 WHERE a='x' AND b='y' AND c>=100 自动使用 (a,b,c) 索引）
  - 最优索引选择（多个索引可用时，选择匹配列数最多的）
- **API**：
  - 单列：createIndex / dropIndex / queryIndex / hasIndex
  - 复合：createCompositeIndex / dropCompositeIndex / queryCompositeIndex / hasCompositeIndex
